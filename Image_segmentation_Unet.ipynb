{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Image_segmentation_Unet.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0exJ9KsDrwck"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "from test_utils import summary, comparator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWitMLSefYL5"
      },
      "source": [
        "<a name='2'></a>\n",
        "Load and Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWpkuq4tfU4i"
      },
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = '/content/drive/MyDrive/'\n",
        "\n",
        "\n",
        "image_path = os.path.join(path, 'data/CameraRGB/')\n",
        "mask_path = os.path.join(path, 'data/CameraMask/')\n",
        "image_list = os.listdir(image_path)\n",
        "mask_list = os.listdir(mask_path)\n",
        "image_list = [image_path+i for i in image_list]\n",
        "mask_list = [mask_path+i for i in mask_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure image_list and mask_list have the same number of existing, valid paths\n",
        "valid_image_paths = [img for img in image_list if os.path.exists(img)]\n",
        "valid_mask_paths = [mask for mask in mask_list if os.path.exists(mask)]\n",
        "\n",
        "# Check if both lists have the same length after filtering\n",
        "if len(valid_image_paths) != len(valid_mask_paths):\n",
        "    print(f\"Mismatch after filtering: {len(valid_image_paths)} images, {len(valid_mask_paths)} masks\")\n",
        "\n",
        "    # Keep only pairs that match by filename\n",
        "    matching_image_paths = []\n",
        "    matching_mask_paths = []\n",
        "\n",
        "    for img_path in valid_image_paths:\n",
        "        mask_path = img_path.replace('CameraRGB', 'CameraMask')  # Adjust pattern if needed\n",
        "        if mask_path in valid_mask_paths:\n",
        "            matching_image_paths.append(img_path)\n",
        "            matching_mask_paths.append(mask_path)\n",
        "\n",
        "    valid_image_paths = matching_image_paths\n",
        "    valid_mask_paths = matching_mask_paths\n",
        "\n",
        "print(f\"Final count - Images: {len(valid_image_paths)}, Masks: {len(valid_mask_paths)}\")"
      ],
      "metadata": {
        "id": "JIWcyZu0pau3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xln87Ey2fYL-"
      },
      "source": [
        "<a name='2-1'></a>\n",
        "Split Your Dataset into Unmasked and Masked Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlzMS0mhmkb1"
      },
      "source": [
        "image_list_ds = tf.data.Dataset.list_files(image_list, shuffle=False)\n",
        "mask_list_ds = tf.data.Dataset.list_files(mask_list, shuffle=False)\n",
        "\n",
        "for path in zip(image_list_ds.take(3), mask_list_ds.take(3)):\n",
        "    print(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_masks = []\n",
        "for image in image_list:\n",
        "    mask_name = image.replace('CameraRGB', 'CameraMask')  # Assuming mask naming follows the same pattern\n",
        "    if mask_name not in mask_list:\n",
        "        missing_masks.append(image)\n",
        "\n",
        "print(f\"Missing masks for {len(missing_masks)} images:\")\n",
        "for missing in missing_masks:\n",
        "    print(missing)"
      ],
      "metadata": {
        "id": "cYXLxIqUqL9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure image_list and mask_list have the same number of existing, valid paths\n",
        "valid_image_paths = [img for img in image_list if os.path.exists(img)]\n",
        "valid_mask_paths = [mask for mask in mask_list if os.path.exists(mask)]\n",
        "\n",
        "# Check if both lists have the same length after filtering\n",
        "if len(valid_image_paths) != len(valid_mask_paths):\n",
        "    print(f\"Mismatch after filtering: {len(valid_image_paths)} images, {len(valid_mask_paths)} masks\")\n",
        "\n",
        "    # Keep only pairs that match by filename\n",
        "    matching_image_paths = []\n",
        "    matching_mask_paths = []\n",
        "\n",
        "    for img_path in valid_image_paths:\n",
        "        mask_path = img_path.replace('CameraRGB', 'CameraMask')  # Adjust pattern if needed\n",
        "        if mask_path in valid_mask_paths:\n",
        "            matching_image_paths.append(img_path)\n",
        "            matching_mask_paths.append(mask_path)\n",
        "\n",
        "    valid_image_paths = matching_image_paths\n",
        "    valid_mask_paths = matching_mask_paths\n",
        "\n",
        "print(f\"Final count - Images: {len(valid_image_paths)}, Masks: {len(valid_mask_paths)}\")"
      ],
      "metadata": {
        "id": "78EfGjEMqORq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNF2Ztii8-Jx"
      },
      "source": [
        "image_filenames = tf.constant(valid_image_paths)\n",
        "masks_filenames = tf.constant(valid_mask_paths)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n",
        "\n",
        "for image, mask in dataset.take(1):\n",
        "    print(image)\n",
        "    print(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNTTO5p1fYMA"
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCoF5AmzfYMA"
      },
      "source": [
        "<a name='2-2'></a>\n",
        "Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUjQfI1wmkkn"
      },
      "source": [
        "def process_path(image_path, mask_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n",
        "    return img, mask\n",
        "\n",
        "def preprocess(image, mask):\n",
        "    input_image = tf.image.resize(image, (96, 128), method='nearest')\n",
        "    input_mask = tf.image.resize(mask, (96, 128), method='nearest')\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "image_ds = dataset.map(process_path)\n",
        "processed_image_ds = image_ds.map(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jREFwsA5w6j",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-5bc67a8f4f19dea5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
        "    conv = Conv2D(n_filters, # Number of filters\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal')(inputs)\n",
        "    conv = Conv2D(n_filters, # Number of filters\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal')(conv)\n",
        "\n",
        "    if dropout_prob > 0:\n",
        "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
        "\n",
        "    if max_pooling:\n",
        "        next_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=2, padding='same')(conv)\n",
        "    else:\n",
        "        next_layer = conv\n",
        "\n",
        "    skip_connection = conv\n",
        "    return next_layer, skip_connection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lzEn-mu6nHa",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4a6bea191d41d977",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
        "    up = Conv2DTranspose(\n",
        "                 n_filters,    # number of filters\n",
        "                 3,    # Kernel size\n",
        "                 strides=2,\n",
        "                 padding='same')(expansive_input)\n",
        "\n",
        "    merge = concatenate([up, contractive_input], axis=3)\n",
        "    conv = Conv2D(n_filters,   # Number of filters\n",
        "                 3,     # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(merge)\n",
        "    conv = Conv2D(n_filters,  # Number of filters\n",
        "                 3,   # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(conv)\n",
        "    return conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv2UCFehHZsh",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-e43cf8104499fbd9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n",
        "    inputs = Input(input_size)\n",
        "    cblock1 = conv_block(inputs, n_filters)\n",
        "    cblock2 = conv_block(cblock1[0], n_filters * 2)\n",
        "    cblock3 = conv_block(cblock2[0], n_filters * 4)\n",
        "    cblock4 = conv_block(cblock3[0], n_filters * 8, dropout_prob=0.3) # Include a dropout_prob of 0.3 for this layer\n",
        "    cblock5 = conv_block(cblock4[0], n_filters * 16, dropout_prob=0.3, max_pooling=False)\n",
        "\n",
        "    ublock6 = upsampling_block(cblock5[0], cblock4[1],  n_filters * 8)\n",
        "    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters * 4)\n",
        "    ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters * 2)\n",
        "    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(ublock9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes,1, padding='same')(conv9)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQYouwm4fYMQ"
      },
      "source": [
        "<a name='3-5'></a>\n",
        "Set Model Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCQIwZlnsDTQ"
      },
      "source": [
        "img_height = 96\n",
        "img_width = 128\n",
        "num_channels = 3\n",
        "\n",
        "unet = unet_model((img_height, img_width, num_channels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBJiP28RfYMR"
      },
      "source": [
        "unet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGfA5_7NtH9i"
      },
      "source": [
        "unet.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSuxeWlSgU5f"
      },
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpFmVX5vgXRj"
      },
      "source": [
        "for image, mask in image_ds.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "    print(mask.shape)\n",
        "display([sample_image, sample_mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqON4c2UGgC4"
      },
      "source": [
        "for image, mask in processed_image_ds.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "    print(mask.shape)\n",
        "display([sample_image, sample_mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sco-8XdVC-gN"
      },
      "source": [
        "<a name='4'></a>\n",
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ne0IowRgcom",
        "outputId": "9fb8a6bf-42b5-4d70-d12d-4ff7e50adc13"
      },
      "source": [
        "EPOCHS = 40\n",
        "VAL_SUBSPLITS = 5\n",
        "BUFFER_SIZE = 500\n",
        "BATCH_SIZE = 32\n",
        "processed_image_ds.batch(BATCH_SIZE)\n",
        "train_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "print(processed_image_ds.element_spec)\n",
        "model_history = unet.fit(train_dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(96, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(96, 128, 1), dtype=tf.uint8, name=None))\n",
            "Epoch 1/40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBgJ2pj_fYMU"
      },
      "source": [
        "<a name='4-1'></a>\n",
        "Create Predicted Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvFEnJrHhmJo"
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqCzmTmnl1lI"
      },
      "source": [
        "plt.plot(model_history.history[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX4uCaP2glMo"
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "    if dataset:\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = unet.predict(image)\n",
        "            display([image[0], mask[0], create_mask(pred_mask)])\n",
        "    else:\n",
        "        display([sample_image, sample_mask,\n",
        "             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qODM_hRhfR5"
      },
      "source": [
        "show_predictions(train_dataset, 6)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}